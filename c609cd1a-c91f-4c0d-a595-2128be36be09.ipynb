{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "803d240b",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "From this dataset that has been obtained via web scraping, can you create a machine learning model to calculate the maximum salary taking into account the job location, competencies required (tag0 to tag4), and the position name? Also perform as detailed as possible the exploratory data analysis. Generate the code snipet to create a user interface ready to select the input data and then get the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab873c",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "To accomplish this task, we'll follow a structured approach:\n",
    "\n",
    "1. **Load and Explore the Dataset**: We'll start by loading the dataset and performing an initial exploration to understand its structure, identify the relevant columns for our model (job location, competencies required, position name, and maximum salary), and check for any data cleaning or preprocessing needs.\n",
    "\n",
    "2. **Data Cleaning and Preprocessing**: Based on our initial exploration, we'll clean and preprocess the data to prepare it for modeling. This may include handling missing values, encoding categorical variables, and normalizing or scaling numerical features.\n",
    "\n",
    "3. **Exploratory Data Analysis (EDA)**: We'll conduct a detailed EDA to uncover patterns, trends, and relationships in the data that could inform our modeling strategy.\n",
    "\n",
    "4. **Feature Engineering**: We'll create new features from the existing data that could improve our model's performance, focusing on the job location, competencies required, and position name.\n",
    "\n",
    "5. **Model Building**: We'll select a suitable machine learning algorithm to predict the maximum salary based on the features. We'll train the model and evaluate its performance using appropriate metrics.\n",
    "\n",
    "6. **User Interface for Model Prediction**: Finally, we'll generate a code snippet to create a user interface that allows users to input the job location, competencies required, and position name to predict the maximum salary.\n",
    "\n",
    "Let's start with step 1: **Load and Explore the Dataset**.\n",
    "\n",
    "I'll begin by loading the dataset and performing an initial exploration to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc3585",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = 'C:\\Users\\ruizg\\OneDrive\\Escritorio\\Python scripts Ironhack - data analysis\\remote_ok_dataset_web_scraping.py'\n",
    "dataframes = read_all_sheets_from_excel(FILEPATH)\n",
    "\n",
    "# print each dataframe name\n",
    "print(\"Dataframe keys of dataframes:\" + \", \".join(dataframes.keys()))\n",
    "\n",
    "for k, v in dataframes.items():\n",
    "    # strip whitespace where possible from column names; need to check if isinstance(x, str) because some column names are numbers\n",
    "    try:\n",
    "        v = v.rename(columns=lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # strip whitespace where possible from cells\n",
    "    try:\n",
    "        v = v.apply(lambda col: col.str.strip() if col.dtype == \"object\" else col)\n",
    "    except:\n",
    "        pass\n",
    "    dataframes[k] = v\n",
    "    print('dataframe: '+ k)\n",
    "    print(v.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e6c27",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The dataset contains a single sheet named \"Data\" with the following relevant columns for our task:\n",
    "\n",
    "- **Company**: The name of the company offering the job.\n",
    "- **Locations/0 to Locations/7**: These columns contain information about the job location. It seems like a job can have multiple locations.\n",
    "- **MaxSalary**: The maximum salary for the job.\n",
    "- **MinSalary**: The minimum salary for the job.\n",
    "- **Tags/0 to Tags/24**: These columns contain tags related to the job, which we can interpret as competencies or skills required for the position.\n",
    "- **Title**: The name of the position.\n",
    "\n",
    "Given this structure, we'll focus on the following columns for our model: the first location column (assuming it's the primary location), the tags (up to tag4 for competencies as requested), and the position name (title). We'll predict the `MaxSalary` based on these features.\n",
    "\n",
    "Next steps:\n",
    "\n",
    "- **Data Cleaning and Preprocessing**: We'll consolidate the location columns into a single primary location column, select the first five tags as competencies, and handle any missing or inconsistent data in these columns and the `MaxSalary` column.\n",
    "- **Exploratory Data Analysis (EDA)**: We'll analyze the distribution of salaries, the frequency of job locations, the most common competencies required, and the relationship between these features and the maximum salary.\n",
    "\n",
    "Let's proceed with data cleaning and preprocessing. I'll start by consolidating the location columns into a single column, selecting the first five tags, and checking for missing values in the relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting relevant columns and consolidating location and tags\n",
    "df = dataframes['Data']\n",
    "\n",
    "# Consolidating the first location column as the primary location\n",
    "df['PrimaryLocation'] = df[['locations/0']].apply(lambda x: x[0], axis=1)\n",
    "\n",
    "# Selecting the first five tags as competencies\n",
    "df['Competencies'] = df[['tags/0', 'tags/1', 'tags/2', 'tags/3', 'tags/4']].apply(lambda x: ', '.join(x.dropna()), axis=1)\n",
    "\n",
    "# Selecting relevant columns for the model\n",
    "df_model = df[['PrimaryLocation', 'Competencies', 'title', 'maxSalary']].copy()\n",
    "\n",
    "# Checking for missing values\n",
    "df_missing = df_model.isnull().sum()\n",
    "print('Missing values in each column:\\n', df_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78413188",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The dataset has the following missing values in the columns relevant to our model:\n",
    "\n",
    "- **PrimaryLocation**: 26 missing values\n",
    "- **Competencies**: No missing values\n",
    "- **Title (Position Name)**: No missing values\n",
    "- **MaxSalary**: 8 missing values\n",
    "\n",
    "To handle these missing values, we have a few options:\n",
    "\n",
    "- For **PrimaryLocation**, we could either drop the rows with missing locations or fill them with a placeholder value like \"Unknown\". Dropping these rows might be preferable if the location is crucial for salary prediction.\n",
    "- For **MaxSalary**, since it's the target variable for our model, we should drop rows where this value is missing, as we can't accurately predict the salary without knowing the actual salary range for some of the positions.\n",
    "\n",
    "Let's proceed by dropping the rows with missing `MaxSalary` and filling the missing `PrimaryLocation` with \"Unknown\". After that, we'll move on to the exploratory data analysis (EDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ca72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "df_model.dropna(subset=['maxSalary'], inplace=True)  # Dropping rows with missing maxSalary\n",
    "df_model['PrimaryLocation'].fillna('Unknown', inplace=True)  # Filling missing locations with 'Unknown'\n",
    "\n",
    "# Checking for missing values again to confirm changes\n",
    "df_missing_updated = df_model.isnull().sum()\n",
    "print('Updated missing values in each column:\\n', df_missing_updated)\n",
    "\n",
    "# Proceeding to EDA\n",
    "print('Proceeding to EDA...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa11ee3a",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The missing values have been successfully handled:\n",
    "\n",
    "- **PrimaryLocation**: Missing values filled with \"Unknown\".\n",
    "- **MaxSalary**: Rows with missing values dropped.\n",
    "\n",
    "With the data cleaned and preprocessed, we're now ready to proceed with the exploratory data analysis (EDA). In the EDA, we'll focus on:\n",
    "\n",
    "- Analyzing the distribution of maximum salaries.\n",
    "- Exploring the frequency of job locations.\n",
    "- Identifying the most common competencies required for the positions.\n",
    "- Investigating the relationship between job locations, competencies, position names, and the maximum salary.\n",
    "\n",
    "Let's start the EDA by analyzing the distribution of maximum salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e511fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setting the background color to white for visibility\n",
    "plt.figure(facecolor='white')\n",
    "\n",
    "# Distribution of maximum salaries\n",
    "sns.histplot(df_model['maxSalary'], bins=30, kde=True)\n",
    "plt.title('Distribution of Maximum Salaries')\n",
    "plt.xlabel('Maximum Salary')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f498781",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "{{images[0]}}\n",
    "\n",
    "The distribution of maximum salaries shows a right-skewed distribution, indicating that most of the jobs have lower maximum salaries, with fewer jobs offering higher maximum salaries. This is a common pattern in salary distributions, where a smaller number of high-paying jobs skew the distribution to the right.\n",
    "\n",
    "Next, let's explore the frequency of job locations to understand where most of the jobs are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ff73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of job locations\n",
    "location_counts = df_model['PrimaryLocation'].value_counts().head(10)  # Top 10 locations\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "sns.barplot(x=location_counts.values, y=location_counts.index, palette='viridis')\n",
    "plt.title('Top 10 Job Locations')\n",
    "plt.xlabel('Number of Jobs')\n",
    "plt.ylabel('Location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff0159",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "{{images[0]}}\n",
    "\n",
    "The bar chart displays the top 10 job locations by the number of jobs. This visualization helps us understand the geographical distribution of the jobs in our dataset, with some locations having a higher concentration of jobs than others.\n",
    "\n",
    "Next, we'll identify the most common competencies required for the positions by analyzing the competencies tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23aeb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Splitting the competencies into individual tags and counting the occurrences\n",
    "competencies_list = df_model['Competencies'].str.split(', ').sum()\n",
    "competency_counts = Counter(competencies_list)\n",
    "\n",
    "# Selecting the top 10 most common competencies\n",
    "most_common_competencies = dict(competency_counts.most_common(10))\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "sns.barplot(x=list(most_common_competencies.values()), y=list(most_common_competencies.keys()), palette='coolwarm')\n",
    "plt.title('Top 10 Most Common Competencies')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Competency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e867bda",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "Let me know how I should continue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b33db59",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "Explore the relationship between job locations and maximum salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8caa2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the relationship between job locations and maximum salaries\n",
    "# We'll use the mean maximum salary for each location for this analysis\n",
    "location_salary_means = df_model.groupby('PrimaryLocation')['maxSalary'].mean().sort_values(ascending=False).head(10)\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "sns.barplot(x=location_salary_means.values, y=location_salary_means.index, palette='magma')\n",
    "plt.title('Top 10 Job Locations by Mean Maximum Salary')\n",
    "plt.xlabel('Mean Maximum Salary')\n",
    "plt.ylabel('Location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d06ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique values in maxSalary column:')\n",
    "print(df_model['maxSalary'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160cea31",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The unique values in the `maxSalary` column are all string representations of salaries with a dollar sign and a 'k' suffix, indicating thousands. To analyze the relationship between job locations and maximum salaries, we need to convert these string values into numeric values.\n",
    "\n",
    "I will proceed to clean the `maxSalary` column by removing the dollar sign and 'k' suffix, and then converting the values to numeric. After cleaning, I'll reattempt the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d221220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the maxSalary column\n",
    "df_model['maxSalary'] = df_model['maxSalary'].str.replace('$', '').str.replace('k', '').astype(int) * 1000\n",
    "\n",
    "# Now, let's try to explore the relationship between job locations and maximum salaries again\n",
    "location_salary_means = df_model.groupby('PrimaryLocation')['maxSalary'].mean().sort_values(ascending=False).head(10)\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "sns.barplot(x=location_salary_means.values, y=location_salary_means.index, palette='magma')\n",
    "plt.title('Top 10 Job Locations by Mean Maximum Salary')\n",
    "plt.xlabel('Mean Maximum Salary')\n",
    "plt.ylabel('Location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4665b16",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "{{images[0]}}\n",
    "\n",
    "The bar chart above illustrates the top 10 job locations by mean maximum salary. This analysis helps us understand which locations offer the highest average maximum salaries for the jobs listed in our dataset. Some locations stand out for offering significantly higher average maximum salaries, indicating potential hotspots for high-paying jobs.\n",
    "\n",
    "If there's anything more you'd like to explore or any other questions, feel free to let me know!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a81d3",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "Compare the maximum salaries for specific job titles across different locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f83b0",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "To compare the maximum salaries for specific job titles across different locations, I'll need to know which job titles you're interested in. Could you provide a list of job titles you'd like to analyze?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d8bef2",
   "metadata": {},
   "source": [
    "**user_message:**\n",
    "\n",
    "What are the top 5 job titles with the highest maximum salaries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cda78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the top 5 job titles with the highest maximum salaries\n",
    "top_job_titles = df_model.groupby('JobTitle')['maxSalary'].max().sort_values(ascending=False).head(5)\n",
    "\n",
    "print(top_job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b95f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_model.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2586cb",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The DataFrame does not contain a column named 'JobTitle'. Instead, it seems the job titles are stored under the column named 'title'. I'll adjust the code to use the correct column name and then proceed to find the top 5 job titles with the highest maximum salaries. Let's try this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the column name and finding the top 5 job titles with the highest maximum salaries\n",
    "top_job_titles = df_model.groupby('title')['maxSalary'].max().sort_values(ascending=False).head(5)\n",
    "\n",
    "print(top_job_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737a7ce",
   "metadata": {},
   "source": [
    "**ai_message:**\n",
    "\n",
    "The top 5 job titles with the highest maximum salaries in the dataset are:\n",
    "\n",
    "- People Operations Generalist: $240,000\n",
    "- Payroll Clerk: $240,000\n",
    "- Senior Sales Manager: $240,000\n",
    "- Executive Assistant: $230,000\n",
    "- International Payroll Administrator: $220,000\n",
    "\n",
    "These job titles represent the highest maximum salary offerings found in the dataset. If you're interested in comparing these salaries across different locations or have any other analysis in mind, please let me know!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
